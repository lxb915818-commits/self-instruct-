æœ¬ä»“åº“å®ç°äº†ä¸€ä¸ªåŸºäº æœ¬åœ°å¤§æ¨¡å‹ï¼ˆvLLM / Transformersï¼‰ ä¸ LangGraph å·¥ä½œæµ çš„è‡ªç›‘ç£æ–‡æœ¬ç”Ÿæˆæµæ°´çº¿ï¼ŒåŠŸèƒ½åŒ…æ‹¬ï¼š

æ ¹æ®å¸¦æ ‡ç­¾çš„æ•æ„Ÿå¥ä¸ä»»åŠ¡æ± è‡ªåŠ¨ç”Ÿæˆæ–°çš„æŒ‡ä»¤ï¼ˆSelf-Instructï¼‰ã€‚

ä½¿ç”¨ç”Ÿæˆçš„æŒ‡ä»¤è¿›ä¸€æ­¥ç”Ÿæˆæ–‡æœ¬æ•°æ®ã€‚

ä½¿ç”¨ ROUGE-L ç›¸ä¼¼åº¦ç­–ç•¥å»é‡ã€è¿‡æ»¤å¹¶ä¿å­˜åˆæ ¼æ–‡æœ¬ã€‚

è‡ªåŠ¨è¿­ä»£ï¼ŒæŒç»­ç”Ÿæˆç›´åˆ°è¾¾åˆ°é¢„æœŸæ•°é‡ï¼ˆé»˜è®¤ 10,000 æ¡ï¼‰ã€‚

æ ¸å¿ƒä»£ç åŒ…æ‹¬ï¼š

self_instruction.pyï¼šæ–‡æœ¬ç”Ÿæˆã€ç›¸ä¼¼åº¦è¿‡æ»¤ã€çŠ¶æ€ç®¡ç†ç­‰ä¸»è¦é€»è¾‘

main_workflow.pyï¼šåŸºäº LangGraph çš„ä¸»æµç¨‹ç¼–æ’

ğŸ“ ç›®å½•ç»“æ„ç¤ºä¾‹
.
â”œâ”€â”€ README.md
â”œâ”€â”€ self_instruction.py
â”œâ”€â”€ main_workflow.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â”œâ”€â”€ sensitive_words.jsonl
â”‚   â”‚   â””â”€â”€ task_pool.jsonl
â”‚   â””â”€â”€ output/
â”‚       â”œâ”€â”€ filtered_new_texts_1125.jsonl
â”‚       â””â”€â”€ rejected_texts.jsonl
â””â”€â”€ requirements.txt

ğŸš€ å¿«é€Ÿå¼€å§‹
1. ç¯å¢ƒè¦æ±‚

Python 3.8+

GPUï¼ˆå»ºè®®ï¼‰+ CUDA

ä¾èµ–åŒ…ï¼š

transformers
vllm
langgraph
rouge
jieba
torch
tqdm

2. å®‰è£…ä¾èµ–
python -m venv venv
source venv/bin/activate

pip install transformers vllm langgraph rouge jieba torch tqdm

3. æ¨¡å‹å‡†å¤‡

ä»£ç åˆå§‹åŒ–æ¨¡å‹æ—¶éœ€è¦æŒ‡å®šæœ¬åœ°è·¯å¾„ï¼Œä¾‹å¦‚ï¼š

model_path = "/path/to/your/Qwen2.5-7B-Instruct"


è¯·æ ¹æ®è‡ªå·±çš„ç¯å¢ƒä¿®æ”¹ self_instruction.py æˆ– main_workflow.py ä¸­çš„è·¯å¾„ã€‚

ğŸ“¦ è¾“å…¥æ•°æ®æ ¼å¼
1. sensitive_words.jsonl

æ¯è¡ŒåŒ…å«ä¸€ä¸ªæ•æ„Ÿå¥åŠå…¶æ ‡ç­¾ï¼š

{"text": "ç¤ºä¾‹æ•æ„Ÿå¥ A", "label": "ç±»åˆ«1"}

2. task_pool.jsonl

ä»»åŠ¡æ± éœ€åŒ…å«ä»»åŠ¡æŒ‡ä»¤ä¸å¯¹åº”æ ‡ç­¾ï¼š

{"instruction": "å†™ä¸€å¥å…³äºXçš„æè¿°ã€‚", "label": "ç±»åˆ«1"}


ç¨‹åºä¼šæ ¹æ®â€œæ ‡ç­¾â€åŒ¹é…ä»»åŠ¡ä¸æ•æ„Ÿå¥ã€‚

ğŸ”§ Command-line å‚æ•°ï¼ˆæ¥è‡ª main_workflow.pyï¼‰
--sensitive_sentences_path   è¾“å…¥æ•æ„Ÿå¥è·¯å¾„
--tasks_path                 è¾“å…¥ä»»åŠ¡æ± è·¯å¾„
--output_dir                 è¾“å‡ºç›®å½•


ç¤ºä¾‹ï¼š

python main_workflow.py \
  --sensitive_sentences_path ./data/input/sensitive_words.jsonl \
  --tasks_path ./data/input/task_pool.jsonl \
  --output_dir ./data/output

ğŸ”„ æ•´ä½“å·¥ä½œæµç¨‹è¯´æ˜

æ•´ä½“æµç¨‹ç”± LangGraph æ„å»ºï¼š

load_original_data
åŠ è½½æ•æ„Ÿå¥å’Œä»»åŠ¡æ± ï¼ˆè‡ªåŠ¨æ ¼å¼æ ¡éªŒï¼‰

select_sensitive_sentence
ä»æ•æ„Ÿå¥é›†åˆä¸­è½®è¯¢/éšæœºé€‰æ‹©ä¸€æ¡

filter_relevant_tasks
ä»ä»»åŠ¡æ± ä¸­ç­›é€‰ 3 æ¡åŒæ ‡ç­¾ä»»åŠ¡ï¼š

1 æ¡éšæœºå¿…é€‰

2 æ¡ ROUGE-L Top2

generate_new_instructions
ä½¿ç”¨å¤§æ¨¡å‹åŸºäºä»»åŠ¡ + æ•æ„Ÿå¥ç”Ÿæˆæ–°æŒ‡ä»¤ï¼ˆSelf-Instructï¼‰

generate_new_texts
ä½¿ç”¨ç”Ÿæˆçš„æŒ‡ä»¤ç”Ÿæˆæ–‡æœ¬

filter_by_rouge
ä½¿ç”¨ ROUGE-Lï¼ˆé˜ˆå€¼ 0.75ï¼‰è¿‡æ»¤é‡å¤æ–‡æœ¬å¹¶å†™å…¥æ–‡ä»¶

check_completion
åˆ¤æ–­æ˜¯å¦è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼ˆé»˜è®¤ 10,000ï¼‰

æœªå®Œæˆåˆ™ç»§ç»­å¾ªç¯ï¼Œç›´åˆ°æ»¡è¶³ç”Ÿæˆç›®æ ‡ã€‚

ğŸ§  æ ¸å¿ƒæ¨¡å—æ‘˜è¦ï¼ˆself_instruction.pyï¼‰
1. init_model(model_path)

åŠ è½½ vLLM æ¨¡å‹å’Œ tokenizerï¼Œè®¾ç½®ç”Ÿæˆå‚æ•°ï¼ˆtemperatureã€top_pã€top_k ç­‰ï¼‰ã€‚

2. load_original_data

åŠ è½½ jsonlï¼Œæ£€æŸ¥å­—æ®µæ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œè§£æä¸ºå†…éƒ¨ç»“æ„ã€‚

3. filter_relevant_tasks

æŒ‰æ ‡ç­¾ç­›é€‰ä»»åŠ¡ + è®¡ç®— ROUGE-L æ’åºé€‰ Top2ã€‚

4. generate_new_instructions

å°†æ•æ„Ÿå¥ä¸ä»»åŠ¡æ¨¡æ¿è¾“å…¥å¤§æ¨¡å‹ï¼Œç”ŸæˆæŒ‡ä»¤ã€‚

5. generate_new_texts

æ ¹æ®æŒ‡ä»¤ç”Ÿæˆè¾“å‡ºæ–‡æœ¬ã€‚

6. filter_by_rouge

è¿‡æ»¤ä¸å†å²æ–‡æœ¬é«˜åº¦ç›¸ä¼¼çš„æ–‡æœ¬ï¼ˆé»˜è®¤é˜ˆå€¼ 0.75ï¼‰ã€‚

ğŸ“¤ è¾“å‡ºæ–‡ä»¶è¯´æ˜
1. filtered_new_texts_1125.jsonl

é€šè¿‡è¿‡æ»¤çš„æ–‡æœ¬ï¼Œå°†ç”¨äºè®­ç»ƒæˆ–ä¸‹æ¸¸ä»»åŠ¡ã€‚

åŒ…æ‹¬å­—æ®µï¼š

text

instruction

label

round_idx

rouge_score

timestamp

2. rejected_texts.jsonl

è¢«è¿‡æ»¤æ‰çš„æ–‡æœ¬ï¼ŒåŒ…æ‹¬ç›¸ä¼¼åº¦ç­‰ä¿¡æ¯ã€‚
